% Encoding: UTF-8
% Try to keep this list in alphabetical order based on citing name

@article{breiman2001random,
  title     = {Random forests},
  author    = {Breiman, Leo},
  journal   = {Machine learning},
  volume    = {45},
  pages     = {5--32},
  year      = {2001},
  publisher = {Springer}
}

@article{choi2017selectingpca,
  issn      = {00905364},
  url       = {http://www.jstor.org/stable/26362952},
  abstract  = {Principal component analysis (PCA) is a well-known tool in multivariate statistics. One significant challenge in using PCA is the choice of the number of principal components. In order to address this challenge, we propose distribution-based methods with exact type 1 error controls for hypothesis testing and construction of confidence intervals for signals in a noisy matrix with finite samples. Assuming Gaussian noise, we derive exact type 1 error controls based on the conditional distribution of the singular values of a Gaussian matrix by utilizing a post-selection inference framework, and extending the approach of [Taylor, Loftus and Tibshirani (2013)] in a PCA setting. In simulation studies, we find that our proposed methods compare well to existing approaches.},
  author    = {Yunjin Choi and Jonathan Taylor and Robert Tibshirani},
  journal   = {The Annals of Statistics},
  number    = {6},
  pages     = {2590--2617},
  publisher = {Institute of Mathematical Statistics},
  title     = {SELECTING THE NUMBER OF PRINCIPAL COMPONENTS: ESTIMATION OF THE TRUE RANK OF A NOISY MATRIX},
  urldate   = {2023-10-26},
  volume    = {45},
  year      = {2017}
}

@article{coleman2022scalable,
  title     = {Scalable and efficient hypothesis testing with random forests},
  author    = {Coleman, Tim and Peng, Wei and Mentch, Lucas},
  journal   = {The Journal of Machine Learning Research},
  volume    = {23},
  number    = {1},
  pages     = {7679--7713},
  year      = {2022},
  publisher = {JMLRORG}
}

@article{hariri2019extended,
  title     = {Extended isolation forest},
  author    = {Hariri, Sahand and Kind, Matias Carrasco and Brunner, Robert J},
  journal   = {IEEE transactions on knowledge and data engineering},
  volume    = {33},
  number    = {4},
  pages     = {1479--1489},
  year      = {2019},
  publisher = {IEEE}
}

@article{Li2023manifold,
  author  = {Li, Adam and Perry, Ronan and Huynh, Chester and Tomita, Tyler M. and Mehta, Ronak and Arroyo, Jesus and Patsolic, Jesse and Falk, Ben and Sarma, Sridevi and Vogelstein, Joshua},
  title   = {Manifold Oblique Random Forests: Towards Closing the Gap on Convolutional Deep Networks},
  journal = {SIAM Journal on Mathematics of Data Science},
  volume  = {5},
  number  = {1},
  pages   = {77-96},
  year    = {2023},
  doi     = {10.1137/21M1449117}
}

@inproceedings{marx2022estimating,
  title        = {Estimating Mutual Information via Geodesic k NN},
  author       = {Marx, Alexander and Fischer, Jonas},
  booktitle    = {Proceedings of the 2022 SIAM International Conference on Data Mining (SDM)},
  pages        = {415--423},
  year         = {2022},
  organization = {SIAM}
}
@article{perry2021random,
  title        = {Random Forests for Adaptive Nearest Neighbor Estimation of Information-Theoretic Quantities},
  author       = {Ronan Perry and Ronak Mehta and Richard Guo and Eva Yezerets and Jesús Arroyo and Mike Powell and Hayden Helm and Cencheng Shen and Joshua T. Vogelstein},
  year         = {2021},
  eprint       = {1907.00325},
  journal      = {arXiv},
  primaryclass = {cs.LG}
}

@inproceedings{Meghana2019_geodesicrf,
  author    = {Madhyastha, Meghana and Li, Percy and Browne, James and Strnadova-Neeley, Veronika and Priebe, Carey E. and Burns, Randal and Vogelstein, Joshua T.},
  title     = {Geodesic Forests},
  year      = {2020},
  isbn      = {9781450379984},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3394486.3403094},
  doi       = {10.1145/3394486.3403094},
  abstract  = {Together with the curse of dimensionality, nonlinear dependencies in large data sets persist as major challenges in data mining tasks. A reliable way to accurately preserve nonlinear structure is to compute geodesic distances between data points. Manifold learning methods, such as Isomap, aim to preserve geodesic distances in a Riemannian manifold. However, as manifold learning algorithms operate on the ambient dimensionality of the data, the essential step of geodesic distance computation is sensitive to high-dimensional noise. Therefore, a direct application of these algorithms to high-dimensional, noisy data often yields unsatisfactory results and does not accurately capture nonlinear structure.We propose an unsupervised random forest approach called geodesic forests (GF) to geodesic distance estimation in linear and nonlinear manifolds with noise. GF operates on low-dimensional sparse linear combinations of features, rather than the full observed dimensionality. To choose the optimal split in a computationally efficient fashion, we developed Fast-BIC, a fast Bayesian Information Criterion statistic for Gaussian mixture models.We additionally propose geodesic precision and geodesic recall as novel evaluation metrics that quantify how well the geodesic distances of a latent manifold are preserved. Empirical results on simulated and real data demonstrate that GF is robust to high-dimensional noise, whereas other methods, such as Isomap, UMAP, and FLANN, quickly deteriorate in such settings. Notably, GF is able to estimate geodesic distances better than other approaches on a real connectome dataset.},
  booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining},
  pages     = {513–-523},
  numpages  = {11},
  keywords  = {random forest, noisy data, unsupervised, manifold learning},
  location  = {Virtual Event, CA, USA},
  series    = {KDD '20}
}

@article{TomitaSPORF2020,
  author  = {Tyler M. Tomita and James Browne and Cencheng Shen and Jaewon Chung and Jesse L. Patsolic and Benjamin Falk and Carey E. Priebe and Jason Yim and Randal Burns and Mauro Maggioni and Joshua T. Vogelstein},
  title   = {Sparse Projection Oblique Randomer Forests},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {104},
  pages   = {1--39},
  url     = {http://jmlr.org/papers/v21/18-664.html}
}

@article{Darbellay1999Entropy,
  title   = {Estimation of the Information by an Adaptive Partitioning of the Observation Space},
  author  = {Georges A. Darbellay and Igor Vajda},
  journal = {IEEE Trans. Inf. Theory},
  year    = {1999},
  volume  = {45},
  pages   = {1315-1321}
}

@article{Kraskov_2004,
  title   = {Estimating mutual information},
  volume  = {69},
  url     = {https://link.aps.org/doi/10.1103/PhysRevE.69.066138},
  doi     = {10.1103/PhysRevE.69.066138},
  number  = {6},
  urldate = {2023-01-27},
  journal = {Physical Review E},
  author  = {Kraskov, Alexander and Stögbauer, Harald and Grassberger, Peter},
  month   = jun,
  year    = {2004},
  note    = {Publisher: American Physical Society},
  pages   = {066138},
  file    = {APS Snapshot:/Users/adam2392/Zotero/storage/GRW23BYU/PhysRevE.69.html:text/html;Full Text PDF:/Users/adam2392/Zotero/storage/NJT9QCVA/Kraskov et al. - 2004 - Estimating mutual information.pdf:application/pdf}
}

@inproceedings{terzi2006efficient,
  title        = {Efficient algorithms for sequence segmentation},
  author       = {Terzi, Evimaria and Tsaparas, Panayiotis},
  booktitle    = {Proceedings of the 2006 SIAM International Conference on Data Mining},
  pages        = {316--327},
  year         = {2006},
  organization = {SIAM}
}

@misc{perry2009crossvalidation,
  title         = {Cross-Validation for Unsupervised Learning},
  author        = {Patrick O. Perry},
  year          = {2009},
  eprint        = {0909.3052},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ME}
}

@article{panda2018learning,
  title   = {Learning Interpretable Characteristic Kernels via Decision Forests},
  author  = {Panda, Sambit and Shen, Cencheng and Vogelstein, Joshua T},
  journal = {arXiv preprint arXiv:1812.00029},
  year    = {2018}
}

@article{trunk1982,
  author    = {Gerard V. Trunk and
               J. O. Coleman},
  title     = {Repeated Hypothesis Testing on a Growing Data Set},
  journal   = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  volume    = {4},
  number    = {3},
  pages     = {343--345},
  year      = {1982},
  url       = {https://doi.org/10.1109/TPAMI.1982.4767256},
  doi       = {10.1109/TPAMI.1982.4767256},
  timestamp = {Tue, 01 Jun 2021 15:21:22 +0200},
  biburl    = {https://dblp.org/rec/journals/pami/TrunkC82.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Bickel_2008,
  title     = {Regularized estimation of large covariance matrices},
  volume    = {36},
  issn      = {0090-5364},
  url       = {http://dx.doi.org/10.1214/009053607000000758},
  doi       = {10.1214/009053607000000758},
  number    = {1},
  journal   = {The Annals of Statistics},
  publisher = {Institute of Mathematical Statistics},
  author    = {Bickel, Peter J. and Levina, Elizaveta},
  year      = {2008},
  month     = feb
}

@article{marron1992exact,
  title={Exact mean integrated squared error},
  author={Marron, J Steve and Wand, Matt P},
  journal={The Annals of Statistics},
  volume={20},
  number={2},
  pages={712--736},
  year={1992},
  publisher={Institute of Mathematical Statistics}
}
